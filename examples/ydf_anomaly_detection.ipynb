{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection\n",
    "\n",
    "This example is based on the anomaly detection tutorial of yggdrasil decision forests. Go to that tutorial for a more complete introduction to anomaly detection and inspecting decision forest anomaly detectors: https://ydf.readthedocs.io/en/latest/tutorial/anomaly_detection/\n",
    "\n",
    "Anomaly detection techniques are non-supervised learning algorithms for identifying rare and unusual patterns in data that deviate significantly from the norm. For example, anomaly detection can be used for fraud detection, network intrusion detection, and fault diagnosis, without the need for defining of abnormal instances.\n",
    "\n",
    "Anomaly detection with decision forests is a straightforward but effective technique for tabular data. The model assigns an anomaly score to each data point, ranging from 0 (normal) to 1 (abnormal). Decision forests also offer interpretability tools and properties, making it easier to understand and characterize detected anomalies.\n",
    "\n",
    "In anomaly detection, labeled examples are used not for training but for evaluating the model. These labels ensure that the model can detect known anomalies.\n",
    "\n",
    "We train and evaluate two anomaly detection models on the UCI Covertype dataset, which describes forest cover types and other geographic attributes of land cells. The first model is trained on pine and willow data. Given that willow is rarer than pine, the model differentiates between them without labels. This first model will then be interpreted and characterize what constitute a pine cover type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ydf  # For learning the anomaly detection model\n",
    "import pandas as pd  # We use Pandas to load small datasets\n",
    "from sklearn import metrics  # Use sklearn to compute AUC\n",
    "from ucimlrepo import fetch_ucirepo  # To download the dataset\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "import seaborn as sns  # For plotting\n",
    "import conifer # conifer\n",
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.WARNING)\n",
    "logger = logging.getLogger('conifer')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://archive.ics.uci.edu/dataset/31/covertype\n",
    "covertype_repo = fetch_ucirepo(id=31)\n",
    "raw_dataset = pd.concat([covertype_repo.data.features, covertype_repo.data.targets], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the columns of interest and clean the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_dataset.copy()\n",
    "\n",
    "# Features of interest\n",
    "features = [\"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n",
    "            \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n",
    "            \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n",
    "            \"Horizontal_Distance_To_Fire_Points\"]\n",
    "dataset = dataset[features + [\"Cover_Type\"]]\n",
    "\n",
    "# Covert type as text\n",
    "dataset[\"Cover_Type\"] = dataset[\"Cover_Type\"].map({\n",
    "    1: \"Spruce/Fir\",\n",
    "    2: \"Lodgepole Pine\",\n",
    "    3: \"Ponderosa Pine\",\n",
    "    4: \"Cottonwood/Willow\",\n",
    "    5: \"Aspen\",\n",
    "    6: \"Douglas-fir\",\n",
    "    7: \"Krummholz\"\n",
    "})\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model is trained on the \"filtered dataset\" than only contain spruce/fir and cottonwood/willow examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset = dataset[dataset[\"Cover_Type\"].isin([\"Spruce/Fir\", \"Cottonwood/Willow\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the spruce/fir cover is much more common than the cottonwood/willow cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset[\"Cover_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a popular anomaly detection decision forest algorithm called isolation forest.\n",
    "\n",
    "## Anomaly detection model\n",
    "\n",
    "The model trained here is a bit smaller (fewer trees and shallower) than the one from the `ydf` tutorial, to make it faster to synthesize and with a smaller FPGA footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ydf.IsolationForestLearner(num_trees=50, max_depth=4, features=features).train(filtered_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then generate \"predictions\" i.e. anomaly scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(filtered_dataset)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plot the model anomaly score's distribution for spruce/fir and cottonwood/willow cover. We se than both distributions are \"separated\", indicating the model's ability to differentiate between the two covers.\n",
    "\n",
    "Note: It's important to note that since cottonwood/willow cover is less frequent, the two distributions are normalized separately. Otherwise, the cottonwood/willow distribution would appear fla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(predictions[filtered_dataset[\"Cover_Type\"] == \"Spruce/Fir\"], label=\"Spruce/Fir\")\n",
    "sns.kdeplot(predictions[filtered_dataset[\"Cover_Type\"] == \"Cottonwood/Willow\"], label=\"Cottonwood/Willow\")\n",
    "plt.xlabel(\"predicted anomaly score\")\n",
    "plt.ylabel(\"distribution\")\n",
    "plt.legend()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to conifer\n",
    "\n",
    "Firstly we'll convert the anomaly detection model to `conifer` with the C++ backend to verify that we get correct outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = conifer.backends.cpp.auto_config()\n",
    "cfg['OutputDir'] = 'prj_ydf_anomaly_detection_cpp'\n",
    "cfg['Precision'] = 'float'\n",
    "cnf_model_cpp = conifer.converters.convert_from_ydf(model, cfg)\n",
    "cnf_model_cpp.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions with the conifer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_predictions = cnf_model_cpp.decision_function(filtered_dataset[features].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare anomaly predictions with `ydf` we have to base-two exponentiate our conifer predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'First 5 conifer predictions  : {2**cnf_predictions[:5][:,0]}')\n",
    "print(f'First 5 yggdrasil predictions: {predictions[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot again the distribution of the anomaly score, adding the predictions from conifer. They should overlap well with the yggdrasil predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(predictions[filtered_dataset[\"Cover_Type\"] == \"Spruce/Fir\"], label=\"Spruce/Fir (yggdrasil)\", color='b')\n",
    "sns.kdeplot(predictions[filtered_dataset[\"Cover_Type\"] == \"Cottonwood/Willow\"], label=\"Cottonwood/Willow (yggdrasil)\", color='orange')\n",
    "sns.kdeplot(2**cnf_predictions[filtered_dataset[\"Cover_Type\"] == \"Spruce/Fir\"], label=\"Spruce/Fir (conifer)\", linestyle='--', color='g')\n",
    "sns.kdeplot(2**cnf_predictions[filtered_dataset[\"Cover_Type\"] == \"Cottonwood/Willow\"], label=\"Cottonwood/Willow (conifer)\", linestyle='--', color='red')\n",
    "plt.xlabel(\"predicted anomaly score\")\n",
    "plt.ylabel(\"distribution\")\n",
    "plt.legend()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPGA\n",
    "\n",
    "Now we saw that we can convert yggdrasil isolation forests and make predictions on CPU with conifer, we'll convert the same model to HLS. For that we also need to choose precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_cfg = conifer.backends.xilinxhls.auto_config(granularity='full')\n",
    "hls_cfg['InputPrecision'] = 'ap_fixed<14,14,AP_RND_CONV,AP_SAT>'     # 14 bit integer based on the range of the input features\n",
    "hls_cfg['ThresholdPrecision'] = 'ap_fixed<16,14,AP_RND_CONV,AP_SAT>' # 14 bit integer + 2 bit fractional to have some resolution between the features\n",
    "hls_cfg['ScorePrecision'] = 'ap_fixed<20,11,AP_RND_CONV,AP_SAT>'     # 11 bit integer + 9 bit fractional to cover both leaf values and normalisation factor\n",
    "cnf_model_hls = conifer.converters.convert_from_ydf(model, hls_cfg)\n",
    "cnf_model_hls.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the fixed precision choices by emulating the predictions and comparing to the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_predictions_hls = cnf_model_hls.decision_function(filtered_dataset[features].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(predictions[filtered_dataset[\"Cover_Type\"] == \"Spruce/Fir\"], label=\"Spruce/Fir (yggdrasil)\", color='b')\n",
    "sns.kdeplot(predictions[filtered_dataset[\"Cover_Type\"] == \"Cottonwood/Willow\"], label=\"Cottonwood/Willow (yggdrasil)\", color='orange')\n",
    "sns.kdeplot(2**cnf_predictions_hls[filtered_dataset[\"Cover_Type\"] == \"Spruce/Fir\"], label=\"Spruce/Fir (conifer)\", linestyle='--', color='g')\n",
    "sns.kdeplot(2**cnf_predictions_hls[filtered_dataset[\"Cover_Type\"] == \"Cottonwood/Willow\"], label=\"Cottonwood/Willow (conifer)\", linestyle='--', color='red')\n",
    "plt.xlabel(\"predicted anomaly score\")\n",
    "plt.ylabel(\"distribution\")\n",
    "plt.legend()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the HLS and HDL synthesis steps so that we can inspect the resources and latency. Check the `hls_accelerator.py` example to see how to target a supported board to produce a binary that can run on an FPGA device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_model_hls.build(synth=True, vsynth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the HLS and HDL Synthesis reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_model_hls.read_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
